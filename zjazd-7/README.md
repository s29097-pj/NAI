# Lunar Lander PPO Agent 

**Rozwizanie zadania z przedmiotu NAI.**

Realizacja Opcji 4: 

*Zaproponuj wasne u偶ycie algorytmu RL* (na bazie rodowiska klasycznego sterowania).

##  Autorzy
**Autorzy:** Micha Maolepszy (s29097), Aleksander Bastek (s27454)

##  Opis Problemu
Celem projektu byo stworzenie autonomicznego agenta, kt贸ry nauczy si sterowa ldownikiem ksi偶ycowym w rodowisku o ograniczonej grawitacji.

**Zadania agenta:**
1.  Stabilizacja lotu (utrzymanie pionu).
2.  Oszczdne gospodarowanie paliwem (kary za cige u偶ywanie silnik贸w).
3.  Precyzyjne ldowanie w wyznaczonej strefie (pomidzy dwiema flagami na wsp贸rzdnych 0,0).
4.  Bezpieczne przyziemienie (prdko bliska zeru w momencie kontaktu z gruntem).

Wybrano rodowisko `LunarLander-v3` z biblioteki **Gymnasium**, poniewa偶 stanowi ono klasyczny problem sterowania cigego (*continuous control*), wymagajcy znacznie bardziej zaawansowanej strategii ni偶 proste gry zrcznociowe.

##  Zastosowana Technologia
W projekcie zdecydowano si na u偶ycie algorytmu **PPO (Proximal Policy Optimization)** zamiast popularnego DQN.

**Dlaczego PPO?**
Algorytm DQN dziaa na dyskretnej przestrzeni akcji i czsto ma problemy z pynnoci ruch贸w w symulacjach fizycznych. PPO (algorytm typu *on-policy*) pozwala na stabilniejsz nauk zachowa wymagajcych precyzji, takich jak delikatne dozowanie cigu silnika tu偶 nad ziemi.

**Parametry modelu:**
* **Jzyk:** Python 3.13
* **rodowisko:** Gymnasium (LunarLander-v3)
* **Framework RL:** Stable-Baselines3
* **Polityka sieci:** MlpPolicy (Multi-Layer Perceptron)
* **Czas treningu:** 300,000 krok贸w symulacji (ok. 15 minut na CPU).

##  Wynik Dziaania
Model osign pen zbie偶no (*explained_variance* > 0.9).
Agent potrafi bezpiecznie wyldowa, wyczy silniki i ustabilizowa pojazd na powierzchni.

**Plik wideo:**
W folderze `wideo_lunar` znajduje si plik `.mp4` prezentujcy przykadowe ldowanie wytrenowanego agenta.

## 锔 Instrukcja Uruchomienia

### 1. Instalacja zale偶noci
Upewnij si, 偶e posiadasz Python 3.x. Zainstaluj biblioteki:
```bash
pip install gymnasium[box2d] stable-baselines3 moviepy shimmy
```
### 2. Trening i Generowanie Wideo (G贸wny skrypt)
Uruchomienie tego skryptu spowoduje wytrenowanie modelu od zera (300k krok贸w), 
zapisanie go oraz wygenerowanie pliku wideo z rezultatem.

```bash
python lunar_lander.py
```

### 3. Podgld na 偶ywo (Live Demo)
Aby zobaczy, jak wytrenowany agent gra w czasie rzeczywistym (w oknie graficznym), uruchom:

```bash
python watch_game.py
```

(Wymaga wczeniejszego wytrenowania modelu i obecnoci pliku ppo_lunar_lander.zip)

##  Referencje
1. [Gymnasium Documentation](https://gymnasium.farama.org/environments/box2d/lunar_lander/)
2. [Stable-Baselines3 Documentation](https://stable-baselines3.readthedocs.io/en/master/modules/ppo.html)
3. OpenAI Gym/Box2D: Silnik fizyczny wykorzystywany do symulacji ldownika.
